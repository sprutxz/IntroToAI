\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{Project 3 Writeup}
\author{Leroy S., Nikil G., Amit R,}

\begin{document}

\maketitle

\section*{The First Task}
    The first task is logistic regression problem using the binary cross entropy loss function. The model we created outputs a probability of whether the diagram is either dangerous or safe. 
    This probability is then compared with the threshold of 0.5 where a probability below is predicts the diagram to be safe and a probability above 0.5 predicts the diagram to be dangerous.
    In order to gather the input data (diagrams), we generated matrices of size 20 by 20 and randomly chose to put down a wire first as a row or col. Subsequently, we added the wires in randomly, 
    alternating wires being put as rows or columns. Each one of the pixels within the diagram were described in the form of a vector in the form of [A, B, C, D] where for each color, one of the variables (A, B, C, or D) 
    would be 1 and the others would be 0. We then flattened the diagram of 20 x 20 = 400 pixels and we got an array of length 1600 where every 4 values describes the color of each pixel. We then added the non-linear features
    to this feature array. \newline

    The non-linear features we added to the model of the first task were constants that represented the percentage of each wire that still remained of the original color. Alternatively, it could be described as a representation 
    of how much each wire had been overlapped with other color wires. The idea behind this features was to create features that gave the model a more concrete idea of when each wire was placed relative to every other wire. 
    These features, in turn, would theoretically allow it to predict whether certain wires were placed before others with higher accuracy. To add non-linearity, I tried functions such as introduction the square function, tanh, 
    and the exponential function. After comparing the increase in accuracy with respect to the model without the non-linear features, I chose the exponential function. In addition, since I didn't want the size of the features to be 
    too high, I chose to take the \[e^{-x}\] of each non-linear feature. 
\section*{The Second Task}
The second task involved a multinomial classification problem where we had to determine, on a given dangerous wire diagram, which wire to cut.
To fulfill this purpose, we used a softmax regression model that output a number for the wire to be cut. The right wire to be cut, as stated in the project 3 writeup, would be te 3rd wire to be placed down.\newline
\newline
We numbered the wires as follows:
\begin{quote}
    \begin{enumerate}
    \item Red
    \item Blue
    \item Yellow
    \item Green
    \end{enumerate}
\end{quote}

\noindent The input space for my model is a 20x20 grid of pixels which are one hot encoded to represent the color of the wire.
This ressults into a feature vector of 1600 elements being 0 or 1.\newline
\newline The output space for my model is a vector of 4 elements, each representing the probability of the wire being cut using the softmax function.
The wire with the highest probability is outputted as the wire to cut.\newline
\newline The model space is the input space plus 4 quadratic features and 2 exponential features.
The quadratic features were obtained by first finding the total pixels each wire color occupies on the diagram. This was then passed through the function $(| x - 19 | + 2)^2$.
The exponential features weere btained by considering the wires that occupied 19 pixels and then finding what wire color was present at the intersesction of these two wires. 
This was one hot encoded and then passed through the function $e^{x}$.\newline
\newline The loss on my model is measured through the categorical cross entropy loss function. 
This loss function is used to measure the error between the predicted output and the actual output. The categorical cross entropy loss function is defined as follows:
\begin{equation}
    CE = -\sum_{i=1}^{N} y_{i} \log(\hat{y}_{i})
\end{equation}

\noindent Here, $y$ is the actual output and $\hat{y}$ is the predicted output. $N$ is the number of data points we have
\section*{Bonus}

\end{document}